---
title: "MA206 Overview"
author: "CPT Jonathan Day"
fontsize: 11pt
geometry: margin=1in
---

# MA206 Redux {.unnumbered .toc-ignore}

*To Cadets:*\
This course, MA206, introduces you to the foundational principles of probability and statistics, emphasizing data literacy and inference. It begins with Block I, covering data types, visualization, and basic probability rules including counting and the behavior of random variables. Block II builds on this by exploring discrete and continuous distributions, the Central Limit Theorem, and tools for one-sample inference such as confidence intervals and hypothesis testing for proportions and means. Finally, Block III develops cadets’ ability to analyze relationships between variables through two-sample tests, linear regression, ANOVA, and goodness-of-fit testing. By the end of the course, cadets will be equipped to make sound, data-driven decisions grounded in statistical reasoning.

*A Note on Technology:*\
In this course the primary tool used for data analysis is R. Throughout this course you will implement techniques for summarizing, visualizing, and analyzing data. The primary focus of this course is not for you to become masters in coding, however building on skills learned in CY105 will help your analysis in understanding how to use information technology to demonstrate successful outcomes in this course.

Of note, some of the functions we use in R require the package *tidyverse*, everytime you begin working in RStudio, the beginning code chunk should resemble:

```{r}
#> echo:FALSE
library(tidyverse)
library(tidyr)
library(patchwork)
```

## BLOCK I: Data and Randomness

### Types of Data, Sampling, and Bias

Fundamental to statistical analysis is understanding the types of data we encounter, the methods we use to collect them, and the potential sources of bias that can undermine the validity of our conclusions. We distinguish between categorical (qualitative) and quantitative (numerical) data, and further classify quantitative data as discrete or continuous. Understanding these distinctions is critical for selecting the correct tools for analysis and interpretation.

We also examine various sampling methods, including simple random sampling, stratified sampling, cluster sampling, and systematic sampling. Each method has strengths and weaknesses depending on the research context, and knowing when to apply each appropriately is a key skill for data-driven decision-making.

Finally, we explore the concept of bias in data collection. We identify common sources such as selection bias, response bias, and measurement bias, and discuss how poor sampling practices or flawed survey design can distort findings. This lesson sets the stage for the rest of the course by highlighting the importance of thoughtful data collection and critical evaluation of data sources.

As an example let us look at a dataset aggregated from over 50,000 diamonds:

```{r}
#| echo: false
set.seed(1991)
data(diamonds)
df <- diamonds %>% sample_n(size=1000)
df %>% head
```
Each of the rows is an individual diamond, generally called an observation. Each of the columns are unique aspects measured for every observation, called variables. Variables are either categorical, qualitative aspects of each measurement, or quantitative, a numbered entry.

### Exploratory Data Analysis

Understanding, communicating, and interpreting your data is *paramount* to any initial data analysis project. These are done through numerous visualizations and summary statistics which we will learn to regularly implement when given any new dataset.

#### One Variable – Visualizations and Summary Statistics

Starting with a variable-by-variable approach is a natural first step. This is done rapidly in R with the following few functions:

```{r}
#| echo: false
p1 <- diamonds %>% sample_n(size=1000) %>% ggplot(aes(x=carat)) + geom_histogram(bins=30) + theme_minimal()
p2 <- diamonds %>% sample_n(size=1000) %>% ggplot(aes(x=depth)) + geom_histogram(bins=30) + theme_minimal()
p3 <- diamonds %>% sample_n(size=1000) %>% ggplot(aes(x=price)) + geom_histogram(bins=30) + theme_minimal()
p1 | p2 | p3
```

Histograms tell us where most of the values for a quantitative variable lie in its given distribution. We can determine *skewness*, a measure of how lopsided the data appear or if there are any asymmetries or *tails*.

```{r}
#| echo: false
p4 <- diamonds %>% sample_n(size=1000) %>% ggplot(aes(x=carat)) + geom_boxplot() + theme_minimal()
p5 <- diamonds %>% sample_n(size=1000) %>% ggplot(aes(x=depth)) + geom_boxplot() + theme_minimal()
p6 <- diamonds %>% sample_n(size=1000) %>% ggplot(aes(x=price)) + geom_boxplot() + theme_minimal()
p4 | p5 | p6
```

Similar to a histogram, a boxplot will tell us exactly where the median, 1st and 3rd quartiles, and outliers exist for any quantitative variable. The 'whiskers' are determined by $1.5 \times IQR$ where the inter-quartile range is the $3rd - 1st$ quartiles.

```{r}
df_summary <- df %>%
  summarise(across(where(is.numeric), list(
    Mean = ~mean(.x, na.rm = TRUE),
    Median = ~median(.x, na.rm = TRUE),
    SD = ~sd(.x, na.rm = TRUE),
    Var = ~var(.x, na.rm = TRUE),
    Min = ~min(.x, na.rm = TRUE),
    Max = ~max(.x, na.rm = TRUE)
  ), .names = "{.col}_{.fn}")) %>%
  pivot_longer(everything(), names_to = c("Variable", "stat"), names_sep = "_") %>%
  pivot_wider(names_from = stat, values_from = value)

print(df_summary)
```
The above are the predominant statistics you want to discern for every quantitative variable in your dataset. The benchmark *location* statistics are the mean, median, max, and min, while the standard deviation and variance are measures of how *spread* out the data are relative to one another.

$$
\begin{align}
\text{Sample Mean: } \ \ & \bar{X} = \frac{1}{n}\sum_{i=1}^n x_i \\
\text{Sample Variance: } \ \ &  S^2 = \frac{1}{n-1}\sum_{i=1}^n ( x_i - \bar{X}  )^2 \\
\text{Sample Standard Deviation:} \ \ & s = \sqrt{\frac{1}{n-1}\sum_{i=1}^n ( x_i - \bar{X} )^2}
\end{align}
$$

***Note: the standard deviation is the square root of the variance***

#### Two Variables – Visualizations and Summary Statistics

```{r}
p7 <- df %>% ggplot(aes(x=carat, y=price, color=clarity)) + geom_point() + theme_minimal()
p8 <- df %>% ggplot(aes(x=table, y=price, color=cut)) + geom_point() + theme_minimal()
p9 <- df %>% ggplot(aes(x=depth, y=price, color=color)) + geom_point() + theme_minimal()
p7 | p8 |p9
```

A scatterplot is the main tool to visualize and identify a relationship between two quantitative variables. Oftentimes, coloring each observation by another categorical variable is a way to maximize effectiveness of a single plot, as you are encoding more information within the same space.

```{r}
p10 <- df %>%
  group_by(cut) %>%
  summarise(avg_price = mean(price)) %>%
  ggplot(aes(x = cut, y = avg_price)) +
  geom_bar(stat = "identity", fill = "pink") +
  labs(
    title = "Average Price by Diamond Cut Quality",
    x = "Diamond Cut",
    y = "Average Price ($)"
  ) +
  theme_minimal()
p11 <- df %>%
  group_by(color) %>%
  summarise(avg_price = mean(price)) %>%
  ggplot(aes(x = color, y = avg_price)) +
  geom_bar(stat = "identity", fill = "skyblue") +
  labs(
    title = "Average Price by Diamond Color Rating",
    x = "Diamond Color",
    y = "Average Price ($)"
  ) +
  theme_minimal()
p12 <- df %>%
  group_by(clarity) %>%
  summarise(avg_price = mean(price)) %>%
  ggplot(aes(x = clarity, y = avg_price)) +
  geom_bar(stat = "identity", fill = "magenta") +
  labs(
    title = "Average Price by Diamond Clarity",
    x = "Diamond Clarity",
    y = "Average Price ($)"
  ) +
  theme_minimal()
p10 | p11 | p12
```

```{r}
cor_df <- df %>%
  select(where(is.numeric)) %>%
  cor(use = "pairwise.complete.obs")

print(cor_df)
```
Correlation is the only multivariate summary statistic we will be using in this course, used to describe how two variables tend to move in tandem with one another. A perfect linear association evokes a correlation of 1, the opposite being a perfect negative association with a correlation of -1. No association is implied by a correlation near 0. 

Mathematically:
> Definition
> For any two variables X,Y, the correlation of X and Y are:
$$
r = \frac{\sum_{i=1}^n (x_i - \bar{x})(y_i-\bar{y})}{\sum_{i=1}^n (x_i - \bar{x})^2\sum_{i=1}^n (y_i - \bar{y})^2}
$$

### Probability

#### Sample Space and Random Experiment ($\Omega$)

A **random experiment** is a process that produces an outcome which cannot be predicted with certainty in advance. It must be well-defined, have more than one possible outcome, and be repeatable under similar conditions. Each performance of the experiment results in a single outcome from the sample space. The **sample space** is the set of all possible outcomes of a random experiment.

------------------------------------------------------------------------

> **Definition:**
>
>   - The **sample space** is the set of all possible outcomes of a random experiment, denoted $\Omega$.
>   - An **event** is a subset of the sample space. It can represent one or more outcomes.
>   - If all outcomes in $\Omega$ are equally likely, then for any event  $A$:

$$
\mathbb{P}(A) = \frac{\text{Number of outcomes in } A}{\text{Total outcomes in } \Omega}
$$

------------------------------------------------------------------------

**Examples:**

-   Tossing a coin once: $\Omega = {\text{Heads}, \text{Tails}}$
-   Rolling a 6-sided die: $\Omega = {1, 2, 3, 4, 5, 6}$
-   Letter grade in MA206: $\Omega = {A, B, C, D, F}$
-   Number of emails received in an hour: $\Omega = {0, 1, 2, \dots}$

------------------------------------------------------------------------

#### Probability Measure ($\mathbb{P}$)

A **probability measure** is a rule, denoted $\mathbb{P}$, that assigns a number between 0 and 1 to every event in a collection of events (called a **sigma-algebra**, denoted \mathcal{F} ). These probabilities must follow three key rules, known as the **axioms of probability**.

------------------------------------------------------------------------

**Axioms of Probability:**

1.  **Non-Negativity**\
    For any event $A$, the probability is never negative:\
    $$
    \mathbb{P}(A) \geq 0
    $$

2.  **Normalization**\
    The probability of one of the events happening over the entire sample space is 1:\
    $$
    \mathbb{P}(\Omega) = 1
    $$

3.  **Additivity (for disjoint events)**\
    If events $A_1, A_2, A_3, \dots $ are **mutually exclusive** (no overlap), then the probability that **any one of them** occurs is the sum of their individual probabilities:\ 
    $$
    \mathbb{P}\left(\bigcup_{i=1}^{\infty} A_i\right) = \mathbb{P}(A_1) + \mathbb{P}(A_2) + \mathbb{P}(A_3) + \cdots
    $$

------------------------------------------------------------------------

**Example (Simple):**\
Let $A$, $B$, and $C$ be outcomes when rolling a die:

-   $A = \{1\}$, $B = \{3\} $, $C = \{5\}$\
-   These are disjoint events (they don't overlap).\
-   Then: $$
    \mathbb{P}(A \cup B \cup C) = \mathbb{P}(A) + \mathbb{P}(B) + \mathbb{P}(C) = \frac{1}{6} + \frac{1}{6} + \frac{1}{6} = \frac{1}{2}
    $$

These three rules form the mathematical foundation of all probability calculations — everything else builds on them.

------------------------------------------------------------------------

**Set Operations on Events:**

-   The **complement** of an event ( A ), written ( A\^c ), consists of all outcomes in ( \Omega ) that are not in ( A ):

$$
\mathbb{P}(A) + \mathbb{P}(A^c) = 1
$$

-   The **intersection** $ A \cap B $ consists of outcomes where both $A$ and $B$ occur.

-   The **union** $A \cup B$ consists of outcomes where either $A$, $B$, or both occur:

$$
\mathbb{P}(A \cup B) = \mathbb{P}(A) + \mathbb{P}(B) - \mathbb{P}(A \cap B)
$$

-   Two events $A$ and $B$ are **disjoint** (mutually exclusive) if they cannot both occur:

$$
A \cap B = \varnothing \quad \text{and} \quad \mathbb{P}(A \cap B) = 0
$$

#### Conditional Probability

For events $A$ and $B$ with $0 < P(B) \le 1 $, the **conditional probability** of $A$ given $B$ is:

$$
P(A \mid B) = \frac{P(A \cap B)}{P(B)}
$$

**Example:** One card is drawn from a standard deck.\
Let $A$: card is a Queen, and $B$: card is a face card.\
Find $P(A)$, $P(B)$, and $P(A \mid B)$.

------------------------------------------------------------------------

#### Law of Total Probability

> **Definition:**\
> If $E_1, \dots, E_n$ is a partition of the sample space (mutually exclusive and exhaustive), then for any event $A$:

$$
P(A) = \sum_{i=1}^{n} P(E_i) P(A \mid E_i)
$$

**Example:**\
A fair die is rolled. Let event A: "an even number is rolled".\
Let:\
- $E_1$: roll is 1 or 2\
- $E_2$: roll is 3 or 4\
- $E_3$: roll is 5 or 6\

Find:\
- $P(A \mid E_1)$, $P(A \mid E_2)$, $P(A \mid E_3)$\
- Then use the Law of Total Probability to find $P(A)$

------------------------------------------------------------------------

#### Bayes' Theorem

> **Definition:**\
> If $E_1, \dots, E_n$ is a partition of the sample space and $P(A) > 0$, then:

$$
P(E_k \mid A) = \frac{P(A \mid E_k) P(E_k)}{\sum_{i=1}^n P(A \mid E_i) P(E_i)}
$$

**Example:**\
Two urns:\
- Urn 1: 1 red, 1 blue\
- Urn 2: 3 red, 1 blue

Pick an urn at random, then draw one ball.\
If the ball is red, what is the probability it came from **Urn 1**?

------------------------------------------------------------------------

#### Counting Principles

Before we can begin a thorough treatment of probability, some concepts in counting are needed to identify four common situations. These arise depending on when things are "allowed" to repeat or the "order" items are chosen in matters. The ability to discern when these **four** situations arise is more than half the battle.

##### Ordered with Replacement

*Think of the number of ways of choosing a 4-digit passcode on your phone.*\
The order of the numbers matters, and you are allowed to repeat the same number. So how many arrangements are there? Since repetition is allowed and order matters, there are 10 digits for each position, giving:

$$
\text{Ordered Arrangements with Replacement} = n^r = 10^4 = 10{,}000
$$

##### Ordered without Replacement

*Think of the number of ways I can create a batting order from 9 position players.*\
The order still matters, but players cannot be repeated. This is a **permutation** — an ordered arrangement without replacement.

$$
{}_nP_r = P(n, r) = \frac{n!}{(n - r)!}
$$

For example, the number of ways to assign the first 3 batting positions from 9 players:

$$
{}_9P_3 = \frac{9!}{(9-3)!} = 9 \times 8 \times 7 = 504
$$

##### Unordered without Replacement

*Think of how many ways you can choose 3 scoops of ice cream from 5 unique flavors without repeats.*\
Because order doesn't matter and repeats aren't allowed, we use **combinations**:

$$
{}_nC_k = \binom{n}{k} = \frac{n!}{k!(n-k)!}
$$

##### Unordered with Replacement

*Think of how many different combinations of 3 scoop ice cream cones you can make with 5 unique flavors while allowing repeats.*\
This is the trickiest scenario. The order doesn't matter, and repetition is allowed. The formula is:

$$
\text{Unordered Arrangements with Replacement} = \binom{r+n-1}{r} = \frac{(r+n-1)!}{r!(n-1)!}
$$

Example: choosing 3 scoops from 5 flavors (with repeats):

$$
\binom{3+5-1}{3} = \binom{7}{3} = 35
$$

This can be understood using the **stars and bars** method: selecting ( r ) scoops with ( n-1 ) dividers.

#### Random Variables, Expectation, and Variance

## BLOCK II: Univariate Inference

### Discrete Random Variables

```         
-   Binomial Distribution: EX, Var(X), PDF, CDF\

-   Geometric Distribution: EX, Var(X), PDF, CDF\
```

### Continuous Random Variables

```         
-   CLT & the Normal Distribution: EX, Var(X), PDF, CDF\

-   Exponential Distribution: EX, Var(X), PDF, CDF\
```

### Confidence Intervals

### One Sample Hypothesis Testing

```         
-   Single Proportion\

-   Single Mean\

-   Experimental Design: Power, T1/II Error\
```

## BLOCK III: Multivariate Inference

### Two Sample Hypothesis Testing

```         
-   Lesson 17: Difference of Proportions\

-   Lesson 18: Multiple Proportions\

-   Lesson 19: Difference of Means\

-   Lesson 20: Paired Data\
```

### Regression

```         
-   Lesson 21: Simple Linear Regression\

-   Lesson 22: Multiple Linear Regression\

-   Lesson 23: Goodness of Fit

-   Lesson 24: ANOVA
```

\newpage

# Preliminaries

## Six Step Method

1.  Describe how the six steps of a statistical investigation apply to a particular statistical study:
    a.  Ask a research question\
    b.  Design a study and collect data\
    c.  Explore the data\
    d.  Draw inferences beyond the data\
    e.  Formulate conclusions\
    f.  Look back and ahead\
2.  Think of and write research questions that could be investigated with a statistical study.\
3.  Identify the observational units and variables in a statistical study.\
4.  Classify variables as categorical or quantitative.
