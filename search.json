[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "MA206 Overview",
    "section": "",
    "text": "To Cadets:\nThis course, MA206, introduces you to the foundational principles of probability and statistics, emphasizing data literacy and inference. It begins with Block I, covering data types, visualization, and basic probability rules including counting and the behavior of random variables. Block II builds on this by exploring discrete and continuous distributions, the Central Limit Theorem, and tools for one-sample inference such as confidence intervals and hypothesis testing for proportions and means. Finally, Block III develops cadets’ ability to analyze relationships between variables through two-sample tests, linear regression, ANOVA, and goodness-of-fit testing. By the end of the course, cadets will be equipped to make sound, data-driven decisions grounded in statistical reasoning.\nA Note on Technology:\nIn this course the primary tool used for data analysis is R. Throughout this course you will implement techniques for summarizing, visualizing, and analyzing data. The primary focus of this course is not for you to become masters in coding, however building on skills learned in CY105 will help your analysis in understanding how to use information technology to demonstrate successful outcomes in this course.\nOf note, some of the functions we use in R require the package tidyverse, everytime you begin working in RStudio, the beginning code chunk should resemble:\n\n#&gt; echo:FALSE\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tidyr)\nlibrary(patchwork)\n\n\n\n\n\nFundamental to statistical analysis is understanding the types of data we encounter, the methods we use to collect them, and the potential sources of bias that can undermine the validity of our conclusions. We distinguish between categorical (qualitative) and quantitative (numerical) data, and further classify quantitative data as discrete or continuous. Understanding these distinctions is critical for selecting the correct tools for analysis and interpretation.\nWe also examine various sampling methods, including simple random sampling, stratified sampling, cluster sampling, and systematic sampling. Each method has strengths and weaknesses depending on the research context, and knowing when to apply each appropriately is a key skill for data-driven decision-making.\nFinally, we explore the concept of bias in data collection. We identify common sources such as selection bias, response bias, and measurement bias, and discuss how poor sampling practices or flawed survey design can distort findings. This lesson sets the stage for the rest of the course by highlighting the importance of thoughtful data collection and critical evaluation of data sources.\nAs an example let us look at a dataset aggregated from over 50,000 diamonds:\n\n\n# A tibble: 6 × 10\n  carat cut       color clarity depth table price     x     y     z\n  &lt;dbl&gt; &lt;ord&gt;     &lt;ord&gt; &lt;ord&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1  1.02 Good      G     VS2      63.8  59    6080  6.34  6.27  4.02\n2  0.31 Ideal     F     VVS1     61.9  53.5   882  4.36  4.39  2.71\n3  0.6  Premium   D     SI2      61.3  61    1428  5.46  5.4   3.33\n4  0.41 Ideal     E     IF       62.1  54    1419  4.75  4.81  2.97\n5  0.72 Very Good H     VS1      62.2  54    2877  5.74  5.76  3.57\n6  1.2  Ideal     F     VS2      62.6  56    8486  6.78  6.73  4.23\n\n\nEach of the rows is an individual diamond, generally called an observation. Each of the columns are unique aspects measured for every observation, called variables. Variables are either categorical, qualitative aspects of each measurement, or quantitative, a numbered entry.\n\n\n\nUnderstanding, communicating, and interpreting your data is paramount to any initial data analysis project. These are done through numerous visualizations and summary statistics which we will learn to regularly implement when given any new dataset.\n\n\nStarting with a variable-by-variable approach is a natural first step. This is done rapidly in R with the following few functions:\n\n\n\n\n\n\n\n\n\nHistograms tell us where most of the values for a quantitative variable lie in its given distribution. We can determine skewness, a measure of how lopsided the data appear or if there are any asymmetries or tails.\n\n\n\n\n\n\n\n\n\nSimilar to a histogram, a boxplot will tell us exactly where the median, 1st and 3rd quartiles, and outliers exist for any quantitative variable. The ‘whiskers’ are determined by \\(1.5 \\times IQR\\) where the inter-quartile range is the \\(3rd - 1st\\) quartiles.\n\ndf_summary &lt;- df %&gt;%\n  summarise(across(where(is.numeric), list(\n    Mean = ~mean(.x, na.rm = TRUE),\n    Median = ~median(.x, na.rm = TRUE),\n    SD = ~sd(.x, na.rm = TRUE),\n    Var = ~var(.x, na.rm = TRUE),\n    Min = ~min(.x, na.rm = TRUE),\n    Max = ~max(.x, na.rm = TRUE)\n  ), .names = \"{.col}_{.fn}\")) %&gt;%\n  pivot_longer(everything(), names_to = c(\"Variable\", \"stat\"), names_sep = \"_\") %&gt;%\n  pivot_wider(names_from = stat, values_from = value)\n\nprint(df_summary)\n\n# A tibble: 7 × 7\n  Variable     Mean  Median       SD          Var    Min      Max\n  &lt;chr&gt;       &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;        &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;\n1 carat       0.790    0.7     0.462        0.213   0.23     3.24\n2 depth      61.8     61.9     1.40         1.97   56.3     68.9 \n3 table      57.5     57       2.26         5.11   50       66   \n4 price    3874.    2387    3913.    15308046.    337    18692   \n5 x           5.72     5.68    1.10         1.21    3.88     9.44\n6 y           5.72     5.68    1.09         1.20    3.9      9.4 \n7 z           3.53     3.52    0.677        0.458   2.39     5.85\n\n\nThe above are the predominant statistics you want to discern for every quantitative variable in your dataset. The benchmark location statistics are the mean, median, max, and min, while the standard deviation and variance are measures of how spread out the data are relative to one another.\n\\[\n\\begin{align}\n\\text{Sample Mean: } \\ \\ & \\bar{X} = \\frac{1}{n}\\sum_{i=1}^n x_i \\\\\n\\text{Sample Variance: } \\ \\ &  S^2 = \\frac{1}{n-1}\\sum_{i=1}^n ( x_i - \\bar{X}  )^2 \\\\\n\\text{Sample Standard Deviation:} \\ \\ & s = \\sqrt{\\frac{1}{n-1}\\sum_{i=1}^n ( x_i - \\bar{X} )^2}\n\\end{align}\n\\]\nNote: the standard deviation is the square root of the variance\n\n\n\n\np7 &lt;- df %&gt;% ggplot(aes(x=carat, y=price, color=clarity)) + geom_point() + theme_minimal()\np8 &lt;- df %&gt;% ggplot(aes(x=table, y=price, color=cut)) + geom_point() + theme_minimal()\np9 &lt;- df %&gt;% ggplot(aes(x=depth, y=price, color=color)) + geom_point() + theme_minimal()\np7 | p8 |p9\n\n\n\n\n\n\n\n\nA scatterplot is the main tool to visualize and identify a relationship between two quantitative variables. Oftentimes, coloring each observation by another categorical variable is a way to maximize effectiveness of a single plot, as you are encoding more information within the same space.\n\np10 &lt;- df %&gt;%\n  group_by(cut) %&gt;%\n  summarise(avg_price = mean(price)) %&gt;%\n  ggplot(aes(x = cut, y = avg_price)) +\n  geom_bar(stat = \"identity\", fill = \"pink\") +\n  labs(\n    title = \"Average Price by Diamond Cut Quality\",\n    x = \"Diamond Cut\",\n    y = \"Average Price ($)\"\n  ) +\n  theme_minimal()\np11 &lt;- df %&gt;%\n  group_by(color) %&gt;%\n  summarise(avg_price = mean(price)) %&gt;%\n  ggplot(aes(x = color, y = avg_price)) +\n  geom_bar(stat = \"identity\", fill = \"skyblue\") +\n  labs(\n    title = \"Average Price by Diamond Color Rating\",\n    x = \"Diamond Color\",\n    y = \"Average Price ($)\"\n  ) +\n  theme_minimal()\np12 &lt;- df %&gt;%\n  group_by(clarity) %&gt;%\n  summarise(avg_price = mean(price)) %&gt;%\n  ggplot(aes(x = clarity, y = avg_price)) +\n  geom_bar(stat = \"identity\", fill = \"magenta\") +\n  labs(\n    title = \"Average Price by Diamond Clarity\",\n    x = \"Diamond Clarity\",\n    y = \"Average Price ($)\"\n  ) +\n  theme_minimal()\np10 | p11 | p12\n\n\n\n\n\n\n\n\n\ncor_df &lt;- df %&gt;%\n  select(where(is.numeric)) %&gt;%\n  cor(use = \"pairwise.complete.obs\")\n\nprint(cor_df)\n\n             carat        depth      table       price          x           y\ncarat  1.000000000 -0.003309893  0.2218141  0.91021728  0.9771650  0.97682747\ndepth -0.003309893  1.000000000 -0.3160834 -0.02418736 -0.0637861 -0.06707873\ntable  0.221814133 -0.316083433  1.0000000  0.16644576  0.2396640  0.23527498\nprice  0.910217282 -0.024187362  0.1664458  1.00000000  0.8763495  0.87899268\nx      0.977165035 -0.063786104  0.2396640  0.87634955  1.0000000  0.99885498\ny      0.976827473 -0.067078728  0.2352750  0.87899268  0.9988550  1.00000000\nz      0.976811196  0.058609118  0.1951975  0.87535333  0.9913793  0.99109238\n               z\ncarat 0.97681120\ndepth 0.05860912\ntable 0.19519747\nprice 0.87535333\nx     0.99137925\ny     0.99109238\nz     1.00000000\n\n\nCorrelation is the only multivariate summary statistic we will be using in this course, used to describe how two variables tend to move in tandem with one another. A perfect linear association evokes a correlation of 1, the opposite being a perfect negative association with a correlation of -1. No association is implied by a correlation near 0.\nMathematically: &gt; Definition &gt; For any two variables X,Y, the correlation of X and Y are: \\[\nr = \\frac{\\sum_{i=1}^n (x_i - \\bar{x})(y_i-\\bar{y})}{\\sum_{i=1}^n (x_i - \\bar{x})^2\\sum_{i=1}^n (y_i - \\bar{y})^2}\n\\]\n\n\n\n\n\n\nA random experiment is a process that produces an outcome which cannot be predicted with certainty in advance. It must be well-defined, have more than one possible outcome, and be repeatable under similar conditions. Each performance of the experiment results in a single outcome from the sample space. The sample space is the set of all possible outcomes of a random experiment.\n\n\nDefinition:\n\nThe sample space is the set of all possible outcomes of a random experiment, denoted \\(\\Omega\\).\nAn event is a subset of the sample space. It can represent one or more outcomes.\nIf all outcomes in \\(\\Omega\\) are equally likely, then for any event \\(A\\):\n\n\n\\[\n\\mathbb{P}(A) = \\frac{\\text{Number of outcomes in } A}{\\text{Total outcomes in } \\Omega}\n\\]\n\nExamples:\n\nTossing a coin once: \\(\\Omega = {\\text{Heads}, \\text{Tails}}\\)\nRolling a 6-sided die: \\(\\Omega = {1, 2, 3, 4, 5, 6}\\)\nLetter grade in MA206: \\(\\Omega = {A, B, C, D, F}\\)\nNumber of emails received in an hour: \\(\\Omega = {0, 1, 2, \\dots}\\)\n\n\n\n\n\nA probability measure is a rule, denoted \\(\\mathbb{P}\\), that assigns a number between 0 and 1 to every event in a collection of events (called a sigma-algebra, denoted ). These probabilities must follow three key rules, known as the axioms of probability.\n\nAxioms of Probability:\n\nNon-Negativity\nFor any event \\(A\\), the probability is never negative:\n\\[\n\\mathbb{P}(A) \\geq 0\n\\]\nNormalization\nThe probability of one of the events happening over the entire sample space is 1:\n\\[\n\\mathbb{P}(\\Omega) = 1\n\\]\nAdditivity (for disjoint events)\nIf events $A_1, A_2, A_3, $ are mutually exclusive (no overlap), then the probability that any one of them occurs is the sum of their individual probabilities:  \\[\n\\mathbb{P}\\left(\\bigcup_{i=1}^{\\infty} A_i\\right) = \\mathbb{P}(A_1) + \\mathbb{P}(A_2) + \\mathbb{P}(A_3) + \\cdots\n\\]\n\n\nExample (Simple):\nLet \\(A\\), \\(B\\), and \\(C\\) be outcomes when rolling a die:\n\n\\(A = \\{1\\}\\), $B = {3} $, \\(C = \\{5\\}\\)\n\nThese are disjoint events (they don’t overlap).\n\nThen: \\[\n\\mathbb{P}(A \\cup B \\cup C) = \\mathbb{P}(A) + \\mathbb{P}(B) + \\mathbb{P}(C) = \\frac{1}{6} + \\frac{1}{6} + \\frac{1}{6} = \\frac{1}{2}\n\\]\n\nThese three rules form the mathematical foundation of all probability calculations — everything else builds on them.\n\nSet Operations on Events:\n\nThe complement of an event ( A ), written ( A^c ), consists of all outcomes in ( ) that are not in ( A ):\n\n\\[\n\\mathbb{P}(A) + \\mathbb{P}(A^c) = 1\n\\]\n\nThe intersection $ A B $ consists of outcomes where both \\(A\\) and \\(B\\) occur.\nThe union \\(A \\cup B\\) consists of outcomes where either \\(A\\), \\(B\\), or both occur:\n\n\\[\n\\mathbb{P}(A \\cup B) = \\mathbb{P}(A) + \\mathbb{P}(B) - \\mathbb{P}(A \\cap B)\n\\]\n\nTwo events \\(A\\) and \\(B\\) are disjoint (mutually exclusive) if they cannot both occur:\n\n\\[\nA \\cap B = \\varnothing \\quad \\text{and} \\quad \\mathbb{P}(A \\cap B) = 0\n\\]\n\n\n\nFor events \\(A\\) and \\(B\\) with $0 &lt; P(B) $, the conditional probability of \\(A\\) given \\(B\\) is:\n\\[\nP(A \\mid B) = \\frac{P(A \\cap B)}{P(B)}\n\\]\nExample: One card is drawn from a standard deck.\nLet \\(A\\): card is a Queen, and \\(B\\): card is a face card.\nFind \\(P(A)\\), \\(P(B)\\), and \\(P(A \\mid B)\\).\n\n\n\n\n\nDefinition:\nIf \\(E_1, \\dots, E_n\\) is a partition of the sample space (mutually exclusive and exhaustive), then for any event \\(A\\):\n\n\\[\nP(A) = \\sum_{i=1}^{n} P(E_i) P(A \\mid E_i)\n\\]\nExample:\nA fair die is rolled. Let event A: “an even number is rolled”.\nLet:\n- \\(E_1\\): roll is 1 or 2\n- \\(E_2\\): roll is 3 or 4\n- \\(E_3\\): roll is 5 or 6\n\nFind:\n- \\(P(A \\mid E_1)\\), \\(P(A \\mid E_2)\\), \\(P(A \\mid E_3)\\)\n- Then use the Law of Total Probability to find \\(P(A)\\)\n\n\n\n\n\nDefinition:\nIf \\(E_1, \\dots, E_n\\) is a partition of the sample space and \\(P(A) &gt; 0\\), then:\n\n\\[\nP(E_k \\mid A) = \\frac{P(A \\mid E_k) P(E_k)}{\\sum_{i=1}^n P(A \\mid E_i) P(E_i)}\n\\]\nExample:\nTwo urns:\n- Urn 1: 1 red, 1 blue\n- Urn 2: 3 red, 1 blue\nPick an urn at random, then draw one ball.\nIf the ball is red, what is the probability it came from Urn 1?\n\n\n\n\nBefore we can begin a thorough treatment of probability, some concepts in counting are needed to identify four common situations. These arise depending on when things are “allowed” to repeat or the “order” items are chosen in matters. The ability to discern when these four situations arise is more than half the battle.\n\n\nThink of the number of ways of choosing a 4-digit passcode on your phone.\nThe order of the numbers matters, and you are allowed to repeat the same number. So how many arrangements are there? Since repetition is allowed and order matters, there are 10 digits for each position, giving:\n\\[\n\\text{Ordered Arrangements with Replacement} = n^r = 10^4 = 10{,}000\n\\]\n\n\n\nThink of the number of ways I can create a batting order from 9 position players.\nThe order still matters, but players cannot be repeated. This is a permutation — an ordered arrangement without replacement.\n\\[\n{}_nP_r = P(n, r) = \\frac{n!}{(n - r)!}\n\\]\nFor example, the number of ways to assign the first 3 batting positions from 9 players:\n\\[\n{}_9P_3 = \\frac{9!}{(9-3)!} = 9 \\times 8 \\times 7 = 504\n\\]\n\n\n\nThink of how many ways you can choose 3 scoops of ice cream from 5 unique flavors without repeats.\nBecause order doesn’t matter and repeats aren’t allowed, we use combinations:\n\\[\n{}_nC_k = \\binom{n}{k} = \\frac{n!}{k!(n-k)!}\n\\]\n\n\n\nThink of how many different combinations of 3 scoop ice cream cones you can make with 5 unique flavors while allowing repeats.\nThis is the trickiest scenario. The order doesn’t matter, and repetition is allowed. The formula is:\n\\[\n\\text{Unordered Arrangements with Replacement} = \\binom{r+n-1}{r} = \\frac{(r+n-1)!}{r!(n-1)!}\n\\]\nExample: choosing 3 scoops from 5 flavors (with repeats):\n\\[\n\\binom{3+5-1}{3} = \\binom{7}{3} = 35\n\\]\nThis can be understood using the stars and bars method: selecting ( r ) scoops with ( n-1 ) dividers.\n\n\n\n\n\n\n\n\n\n\n\n-   Binomial Distribution: EX, Var(X), PDF, CDF\\\n\n-   Geometric Distribution: EX, Var(X), PDF, CDF\\\n\n\n\n-   CLT & the Normal Distribution: EX, Var(X), PDF, CDF\\\n\n-   Exponential Distribution: EX, Var(X), PDF, CDF\\\n\n\n\n\n\n\n-   Single Proportion\\\n\n-   Single Mean\\\n\n-   Experimental Design: Power, T1/II Error\\\n\n\n\n\n\n\n-   Lesson 17: Difference of Proportions\\\n\n-   Lesson 18: Multiple Proportions\\\n\n-   Lesson 19: Difference of Means\\\n\n-   Lesson 20: Paired Data\\\n\n\n\n-   Lesson 21: Simple Linear Regression\\\n\n-   Lesson 22: Multiple Linear Regression\\\n\n-   Lesson 23: Goodness of Fit\n\n-   Lesson 24: ANOVA"
  },
  {
    "objectID": "index.html#block-i-data-and-randomness",
    "href": "index.html#block-i-data-and-randomness",
    "title": "MA206 Overview",
    "section": "",
    "text": "Fundamental to statistical analysis is understanding the types of data we encounter, the methods we use to collect them, and the potential sources of bias that can undermine the validity of our conclusions. We distinguish between categorical (qualitative) and quantitative (numerical) data, and further classify quantitative data as discrete or continuous. Understanding these distinctions is critical for selecting the correct tools for analysis and interpretation.\nWe also examine various sampling methods, including simple random sampling, stratified sampling, cluster sampling, and systematic sampling. Each method has strengths and weaknesses depending on the research context, and knowing when to apply each appropriately is a key skill for data-driven decision-making.\nFinally, we explore the concept of bias in data collection. We identify common sources such as selection bias, response bias, and measurement bias, and discuss how poor sampling practices or flawed survey design can distort findings. This lesson sets the stage for the rest of the course by highlighting the importance of thoughtful data collection and critical evaluation of data sources.\nAs an example let us look at a dataset aggregated from over 50,000 diamonds:\n\n\n# A tibble: 6 × 10\n  carat cut       color clarity depth table price     x     y     z\n  &lt;dbl&gt; &lt;ord&gt;     &lt;ord&gt; &lt;ord&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1  1.02 Good      G     VS2      63.8  59    6080  6.34  6.27  4.02\n2  0.31 Ideal     F     VVS1     61.9  53.5   882  4.36  4.39  2.71\n3  0.6  Premium   D     SI2      61.3  61    1428  5.46  5.4   3.33\n4  0.41 Ideal     E     IF       62.1  54    1419  4.75  4.81  2.97\n5  0.72 Very Good H     VS1      62.2  54    2877  5.74  5.76  3.57\n6  1.2  Ideal     F     VS2      62.6  56    8486  6.78  6.73  4.23\n\n\nEach of the rows is an individual diamond, generally called an observation. Each of the columns are unique aspects measured for every observation, called variables. Variables are either categorical, qualitative aspects of each measurement, or quantitative, a numbered entry.\n\n\n\nUnderstanding, communicating, and interpreting your data is paramount to any initial data analysis project. These are done through numerous visualizations and summary statistics which we will learn to regularly implement when given any new dataset.\n\n\nStarting with a variable-by-variable approach is a natural first step. This is done rapidly in R with the following few functions:\n\n\n\n\n\n\n\n\n\nHistograms tell us where most of the values for a quantitative variable lie in its given distribution. We can determine skewness, a measure of how lopsided the data appear or if there are any asymmetries or tails.\n\n\n\n\n\n\n\n\n\nSimilar to a histogram, a boxplot will tell us exactly where the median, 1st and 3rd quartiles, and outliers exist for any quantitative variable. The ‘whiskers’ are determined by \\(1.5 \\times IQR\\) where the inter-quartile range is the \\(3rd - 1st\\) quartiles.\n\ndf_summary &lt;- df %&gt;%\n  summarise(across(where(is.numeric), list(\n    Mean = ~mean(.x, na.rm = TRUE),\n    Median = ~median(.x, na.rm = TRUE),\n    SD = ~sd(.x, na.rm = TRUE),\n    Var = ~var(.x, na.rm = TRUE),\n    Min = ~min(.x, na.rm = TRUE),\n    Max = ~max(.x, na.rm = TRUE)\n  ), .names = \"{.col}_{.fn}\")) %&gt;%\n  pivot_longer(everything(), names_to = c(\"Variable\", \"stat\"), names_sep = \"_\") %&gt;%\n  pivot_wider(names_from = stat, values_from = value)\n\nprint(df_summary)\n\n# A tibble: 7 × 7\n  Variable     Mean  Median       SD          Var    Min      Max\n  &lt;chr&gt;       &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;        &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;\n1 carat       0.790    0.7     0.462        0.213   0.23     3.24\n2 depth      61.8     61.9     1.40         1.97   56.3     68.9 \n3 table      57.5     57       2.26         5.11   50       66   \n4 price    3874.    2387    3913.    15308046.    337    18692   \n5 x           5.72     5.68    1.10         1.21    3.88     9.44\n6 y           5.72     5.68    1.09         1.20    3.9      9.4 \n7 z           3.53     3.52    0.677        0.458   2.39     5.85\n\n\nThe above are the predominant statistics you want to discern for every quantitative variable in your dataset. The benchmark location statistics are the mean, median, max, and min, while the standard deviation and variance are measures of how spread out the data are relative to one another.\n\\[\n\\begin{align}\n\\text{Sample Mean: } \\ \\ & \\bar{X} = \\frac{1}{n}\\sum_{i=1}^n x_i \\\\\n\\text{Sample Variance: } \\ \\ &  S^2 = \\frac{1}{n-1}\\sum_{i=1}^n ( x_i - \\bar{X}  )^2 \\\\\n\\text{Sample Standard Deviation:} \\ \\ & s = \\sqrt{\\frac{1}{n-1}\\sum_{i=1}^n ( x_i - \\bar{X} )^2}\n\\end{align}\n\\]\nNote: the standard deviation is the square root of the variance\n\n\n\n\np7 &lt;- df %&gt;% ggplot(aes(x=carat, y=price, color=clarity)) + geom_point() + theme_minimal()\np8 &lt;- df %&gt;% ggplot(aes(x=table, y=price, color=cut)) + geom_point() + theme_minimal()\np9 &lt;- df %&gt;% ggplot(aes(x=depth, y=price, color=color)) + geom_point() + theme_minimal()\np7 | p8 |p9\n\n\n\n\n\n\n\n\nA scatterplot is the main tool to visualize and identify a relationship between two quantitative variables. Oftentimes, coloring each observation by another categorical variable is a way to maximize effectiveness of a single plot, as you are encoding more information within the same space.\n\np10 &lt;- df %&gt;%\n  group_by(cut) %&gt;%\n  summarise(avg_price = mean(price)) %&gt;%\n  ggplot(aes(x = cut, y = avg_price)) +\n  geom_bar(stat = \"identity\", fill = \"pink\") +\n  labs(\n    title = \"Average Price by Diamond Cut Quality\",\n    x = \"Diamond Cut\",\n    y = \"Average Price ($)\"\n  ) +\n  theme_minimal()\np11 &lt;- df %&gt;%\n  group_by(color) %&gt;%\n  summarise(avg_price = mean(price)) %&gt;%\n  ggplot(aes(x = color, y = avg_price)) +\n  geom_bar(stat = \"identity\", fill = \"skyblue\") +\n  labs(\n    title = \"Average Price by Diamond Color Rating\",\n    x = \"Diamond Color\",\n    y = \"Average Price ($)\"\n  ) +\n  theme_minimal()\np12 &lt;- df %&gt;%\n  group_by(clarity) %&gt;%\n  summarise(avg_price = mean(price)) %&gt;%\n  ggplot(aes(x = clarity, y = avg_price)) +\n  geom_bar(stat = \"identity\", fill = \"magenta\") +\n  labs(\n    title = \"Average Price by Diamond Clarity\",\n    x = \"Diamond Clarity\",\n    y = \"Average Price ($)\"\n  ) +\n  theme_minimal()\np10 | p11 | p12\n\n\n\n\n\n\n\n\n\ncor_df &lt;- df %&gt;%\n  select(where(is.numeric)) %&gt;%\n  cor(use = \"pairwise.complete.obs\")\n\nprint(cor_df)\n\n             carat        depth      table       price          x           y\ncarat  1.000000000 -0.003309893  0.2218141  0.91021728  0.9771650  0.97682747\ndepth -0.003309893  1.000000000 -0.3160834 -0.02418736 -0.0637861 -0.06707873\ntable  0.221814133 -0.316083433  1.0000000  0.16644576  0.2396640  0.23527498\nprice  0.910217282 -0.024187362  0.1664458  1.00000000  0.8763495  0.87899268\nx      0.977165035 -0.063786104  0.2396640  0.87634955  1.0000000  0.99885498\ny      0.976827473 -0.067078728  0.2352750  0.87899268  0.9988550  1.00000000\nz      0.976811196  0.058609118  0.1951975  0.87535333  0.9913793  0.99109238\n               z\ncarat 0.97681120\ndepth 0.05860912\ntable 0.19519747\nprice 0.87535333\nx     0.99137925\ny     0.99109238\nz     1.00000000\n\n\nCorrelation is the only multivariate summary statistic we will be using in this course, used to describe how two variables tend to move in tandem with one another. A perfect linear association evokes a correlation of 1, the opposite being a perfect negative association with a correlation of -1. No association is implied by a correlation near 0.\nMathematically: &gt; Definition &gt; For any two variables X,Y, the correlation of X and Y are: \\[\nr = \\frac{\\sum_{i=1}^n (x_i - \\bar{x})(y_i-\\bar{y})}{\\sum_{i=1}^n (x_i - \\bar{x})^2\\sum_{i=1}^n (y_i - \\bar{y})^2}\n\\]\n\n\n\n\n\n\nA random experiment is a process that produces an outcome which cannot be predicted with certainty in advance. It must be well-defined, have more than one possible outcome, and be repeatable under similar conditions. Each performance of the experiment results in a single outcome from the sample space. The sample space is the set of all possible outcomes of a random experiment.\n\n\nDefinition:\n\nThe sample space is the set of all possible outcomes of a random experiment, denoted \\(\\Omega\\).\nAn event is a subset of the sample space. It can represent one or more outcomes.\nIf all outcomes in \\(\\Omega\\) are equally likely, then for any event \\(A\\):\n\n\n\\[\n\\mathbb{P}(A) = \\frac{\\text{Number of outcomes in } A}{\\text{Total outcomes in } \\Omega}\n\\]\n\nExamples:\n\nTossing a coin once: \\(\\Omega = {\\text{Heads}, \\text{Tails}}\\)\nRolling a 6-sided die: \\(\\Omega = {1, 2, 3, 4, 5, 6}\\)\nLetter grade in MA206: \\(\\Omega = {A, B, C, D, F}\\)\nNumber of emails received in an hour: \\(\\Omega = {0, 1, 2, \\dots}\\)\n\n\n\n\n\nA probability measure is a rule, denoted \\(\\mathbb{P}\\), that assigns a number between 0 and 1 to every event in a collection of events (called a sigma-algebra, denoted ). These probabilities must follow three key rules, known as the axioms of probability.\n\nAxioms of Probability:\n\nNon-Negativity\nFor any event \\(A\\), the probability is never negative:\n\\[\n\\mathbb{P}(A) \\geq 0\n\\]\nNormalization\nThe probability of one of the events happening over the entire sample space is 1:\n\\[\n\\mathbb{P}(\\Omega) = 1\n\\]\nAdditivity (for disjoint events)\nIf events $A_1, A_2, A_3, $ are mutually exclusive (no overlap), then the probability that any one of them occurs is the sum of their individual probabilities:  \\[\n\\mathbb{P}\\left(\\bigcup_{i=1}^{\\infty} A_i\\right) = \\mathbb{P}(A_1) + \\mathbb{P}(A_2) + \\mathbb{P}(A_3) + \\cdots\n\\]\n\n\nExample (Simple):\nLet \\(A\\), \\(B\\), and \\(C\\) be outcomes when rolling a die:\n\n\\(A = \\{1\\}\\), $B = {3} $, \\(C = \\{5\\}\\)\n\nThese are disjoint events (they don’t overlap).\n\nThen: \\[\n\\mathbb{P}(A \\cup B \\cup C) = \\mathbb{P}(A) + \\mathbb{P}(B) + \\mathbb{P}(C) = \\frac{1}{6} + \\frac{1}{6} + \\frac{1}{6} = \\frac{1}{2}\n\\]\n\nThese three rules form the mathematical foundation of all probability calculations — everything else builds on them.\n\nSet Operations on Events:\n\nThe complement of an event ( A ), written ( A^c ), consists of all outcomes in ( ) that are not in ( A ):\n\n\\[\n\\mathbb{P}(A) + \\mathbb{P}(A^c) = 1\n\\]\n\nThe intersection $ A B $ consists of outcomes where both \\(A\\) and \\(B\\) occur.\nThe union \\(A \\cup B\\) consists of outcomes where either \\(A\\), \\(B\\), or both occur:\n\n\\[\n\\mathbb{P}(A \\cup B) = \\mathbb{P}(A) + \\mathbb{P}(B) - \\mathbb{P}(A \\cap B)\n\\]\n\nTwo events \\(A\\) and \\(B\\) are disjoint (mutually exclusive) if they cannot both occur:\n\n\\[\nA \\cap B = \\varnothing \\quad \\text{and} \\quad \\mathbb{P}(A \\cap B) = 0\n\\]\n\n\n\nFor events \\(A\\) and \\(B\\) with $0 &lt; P(B) $, the conditional probability of \\(A\\) given \\(B\\) is:\n\\[\nP(A \\mid B) = \\frac{P(A \\cap B)}{P(B)}\n\\]\nExample: One card is drawn from a standard deck.\nLet \\(A\\): card is a Queen, and \\(B\\): card is a face card.\nFind \\(P(A)\\), \\(P(B)\\), and \\(P(A \\mid B)\\).\n\n\n\n\n\nDefinition:\nIf \\(E_1, \\dots, E_n\\) is a partition of the sample space (mutually exclusive and exhaustive), then for any event \\(A\\):\n\n\\[\nP(A) = \\sum_{i=1}^{n} P(E_i) P(A \\mid E_i)\n\\]\nExample:\nA fair die is rolled. Let event A: “an even number is rolled”.\nLet:\n- \\(E_1\\): roll is 1 or 2\n- \\(E_2\\): roll is 3 or 4\n- \\(E_3\\): roll is 5 or 6\n\nFind:\n- \\(P(A \\mid E_1)\\), \\(P(A \\mid E_2)\\), \\(P(A \\mid E_3)\\)\n- Then use the Law of Total Probability to find \\(P(A)\\)\n\n\n\n\n\nDefinition:\nIf \\(E_1, \\dots, E_n\\) is a partition of the sample space and \\(P(A) &gt; 0\\), then:\n\n\\[\nP(E_k \\mid A) = \\frac{P(A \\mid E_k) P(E_k)}{\\sum_{i=1}^n P(A \\mid E_i) P(E_i)}\n\\]\nExample:\nTwo urns:\n- Urn 1: 1 red, 1 blue\n- Urn 2: 3 red, 1 blue\nPick an urn at random, then draw one ball.\nIf the ball is red, what is the probability it came from Urn 1?\n\n\n\n\nBefore we can begin a thorough treatment of probability, some concepts in counting are needed to identify four common situations. These arise depending on when things are “allowed” to repeat or the “order” items are chosen in matters. The ability to discern when these four situations arise is more than half the battle.\n\n\nThink of the number of ways of choosing a 4-digit passcode on your phone.\nThe order of the numbers matters, and you are allowed to repeat the same number. So how many arrangements are there? Since repetition is allowed and order matters, there are 10 digits for each position, giving:\n\\[\n\\text{Ordered Arrangements with Replacement} = n^r = 10^4 = 10{,}000\n\\]\n\n\n\nThink of the number of ways I can create a batting order from 9 position players.\nThe order still matters, but players cannot be repeated. This is a permutation — an ordered arrangement without replacement.\n\\[\n{}_nP_r = P(n, r) = \\frac{n!}{(n - r)!}\n\\]\nFor example, the number of ways to assign the first 3 batting positions from 9 players:\n\\[\n{}_9P_3 = \\frac{9!}{(9-3)!} = 9 \\times 8 \\times 7 = 504\n\\]\n\n\n\nThink of how many ways you can choose 3 scoops of ice cream from 5 unique flavors without repeats.\nBecause order doesn’t matter and repeats aren’t allowed, we use combinations:\n\\[\n{}_nC_k = \\binom{n}{k} = \\frac{n!}{k!(n-k)!}\n\\]\n\n\n\nThink of how many different combinations of 3 scoop ice cream cones you can make with 5 unique flavors while allowing repeats.\nThis is the trickiest scenario. The order doesn’t matter, and repetition is allowed. The formula is:\n\\[\n\\text{Unordered Arrangements with Replacement} = \\binom{r+n-1}{r} = \\frac{(r+n-1)!}{r!(n-1)!}\n\\]\nExample: choosing 3 scoops from 5 flavors (with repeats):\n\\[\n\\binom{3+5-1}{3} = \\binom{7}{3} = 35\n\\]\nThis can be understood using the stars and bars method: selecting ( r ) scoops with ( n-1 ) dividers."
  },
  {
    "objectID": "index.html#block-ii-univariate-inference",
    "href": "index.html#block-ii-univariate-inference",
    "title": "MA206 Overview",
    "section": "",
    "text": "-   Binomial Distribution: EX, Var(X), PDF, CDF\\\n\n-   Geometric Distribution: EX, Var(X), PDF, CDF\\\n\n\n\n-   CLT & the Normal Distribution: EX, Var(X), PDF, CDF\\\n\n-   Exponential Distribution: EX, Var(X), PDF, CDF\\\n\n\n\n\n\n\n-   Single Proportion\\\n\n-   Single Mean\\\n\n-   Experimental Design: Power, T1/II Error\\"
  },
  {
    "objectID": "index.html#block-iii-multivariate-inference",
    "href": "index.html#block-iii-multivariate-inference",
    "title": "MA206 Overview",
    "section": "",
    "text": "-   Lesson 17: Difference of Proportions\\\n\n-   Lesson 18: Multiple Proportions\\\n\n-   Lesson 19: Difference of Means\\\n\n-   Lesson 20: Paired Data\\\n\n\n\n-   Lesson 21: Simple Linear Regression\\\n\n-   Lesson 22: Multiple Linear Regression\\\n\n-   Lesson 23: Goodness of Fit\n\n-   Lesson 24: ANOVA"
  },
  {
    "objectID": "index.html#six-step-method",
    "href": "index.html#six-step-method",
    "title": "MA206 Overview",
    "section": "Six Step Method",
    "text": "Six Step Method\n\nDescribe how the six steps of a statistical investigation apply to a particular statistical study:\n\nAsk a research question\n\nDesign a study and collect data\n\nExplore the data\n\nDraw inferences beyond the data\n\nFormulate conclusions\n\nLook back and ahead\n\n\nThink of and write research questions that could be investigated with a statistical study.\n\nIdentify the observational units and variables in a statistical study.\n\nClassify variables as categorical or quantitative."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  }
]